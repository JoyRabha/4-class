{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pyedflib\n",
    "from matplotlib import pyplot as plt\n",
    "from nitime import utils\n",
    "from nitime import algorithms as alg\n",
    "from nitime.timeseries import TimeSeries\n",
    "from nitime.viz import plot_tseries\n",
    "import csv\n",
    "import pywt\n",
    "import scipy.stats as sp\n",
    "from scipy import signal\n",
    "from spectrum import *\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from wyrm import processing as proc\n",
    "from wyrm.types import Data\n",
    "from wyrm.processing import select_channels\n",
    "from wyrm.processing import swapaxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_files_location = '4_class_data'\n",
    "files1  = [f for f in listdir(data_files_location)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['k6b_markers.csv',\n",
       " 'l1b_data.csv',\n",
       " 'l1b_markers.csv',\n",
       " 'k3b_markers.csv',\n",
       " 'k3b_data.csv',\n",
       " 'k6b_data.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "subjects = ['k3b','k6b','l1b']\n",
    "location = data_files_location + '/' + subjects[1] + '_markers.csv'\n",
    "mark = np.genfromtxt (location, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ca = [1,2,3,4,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ca[0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wavelet-Domain Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavelet_features(epoch,channels):\n",
    "    cA_values = []\n",
    "    cD_values = []\n",
    "    cA_mean = []\n",
    "    cA_std = []\n",
    "    cA_Energy =[]\n",
    "    cD_mean = []\n",
    "    cD_std = []\n",
    "    cD_Energy = []\n",
    "    Entropy_D = []\n",
    "    Entropy_A = []\n",
    "    for i in range(channels):\n",
    "        cA,cD=pywt.dwt(epoch[i,:],'coif1')\n",
    "        cA_values.append(cA)\n",
    "        cD_values.append(cD)\t\t#calculating the coefficients of wavelet transform.\n",
    "    for x in range(channels):   \n",
    "        cA_mean.append(np.mean(cA_values[x]))\n",
    "        cA_std.append(abs(np.std(cA_values[x])))\n",
    "        cA_Energy.append(abs(np.sum(np.square(cA_values[x]))))\n",
    "        cD_mean.append(np.mean(cD_values[x]))\t\t# mean and standard deviation values of coefficents of each channel is stored .\n",
    "        cD_std.append(abs(np.std(cD_values[x])))\n",
    "        cD_Energy.append(abs(np.sum(np.square(cD_values[x]))))\n",
    "        Entropy_D.append(abs(np.sum(np.square(cD_values[x]) * np.log(np.square(cD_values[x])))))\n",
    "        Entropy_A.append(abs(np.sum(np.square(cA_values[x]) * np.log(np.square(cA_values[x]))))) \n",
    "    return cA_std[25],cA_std[26],cA_std[27],cA_std[28],cA_std[29],cA_std[30],cA_std[31],cA_std[32],cA_std[33],cA_std[34],cA_std[35],cD_std[25],cD_std[26],cD_std[27],cD_std[28],cD_std[29],cD_std[30],cD_std[31],cD_std[32],cD_std[33],cD_std[34],cD_std[35],cA_Energy[25],cA_Energy[26],cA_Energy[27],cA_Energy[28],cA_Energy[29],cA_Energy[30],cA_Energy[31],cA_Energy[32],cA_Energy[33],cA_Energy[34],cA_Energy[35],cD_Energy[25],cD_Energy[26],cD_Energy[27],cD_Energy[28],cD_Energy[29],cD_Energy[30],cD_Energy[31],cD_Energy[32],cD_Energy[33],cD_Energy[34],cD_Energy[35],Entropy_D[25],Entropy_D[26],Entropy_D[27],Entropy_D[28],Entropy_D[29],Entropy_D[30],Entropy_D[31],Entropy_D[32],Entropy_D[33],Entropy_D[34],Entropy_D[35],Entropy_A[25],Entropy_A[26],Entropy_A[27],Entropy_A[28],Entropy_A[29],Entropy_A[30],Entropy_A[31],Entropy_A[32],Entropy_A[33],Entropy_A[34],Entropy_A[35],np.sum(cA_mean)/channels,np.sum(cA_std)/channels,np.sum(cD_mean)/channels,np.sum(cD_std)/channels,np.sum(cA_Energy)/channels,np.sum(cD_Energy)/channels,np.sum(Entropy_A)/channels,np.sum(Entropy_D)/channels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency domain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "def maxPwelch(data_win,Fs,channels):\n",
    "    BandF = [0.1, 3, 7, 12, 30]\n",
    "    PMax = np.zeros([channels,(len(BandF)-1)]);\n",
    "    feature = []\n",
    "    for j in range(60):\n",
    "        f,Psd = signal.welch(epoch[j,:], 250)\n",
    "        for i in range(len(f)):\n",
    "            if f[i] > 30:\n",
    "                feature.append(sum(Psd[0:i])/i)\n",
    "            break\n",
    "    return feature[25:36] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoregressive model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autogressiveModelParametersBurg(labels,channels):\n",
    "    feature = []\n",
    "    feature1 = []\n",
    "    model_order = 6\n",
    "    for i in range(channels):\n",
    "        AR, rho, ref = arburg(labels[i], model_order)\n",
    "        feature.append(AR);\n",
    "    for j in range(channels):\n",
    "        for i in range(model_order):\n",
    "            feature1.append(feature[j][i])\n",
    "\n",
    "    return feature1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_variance(filtered_epoch,channels):\n",
    "    return abs(np.std(epoch[25])),abs(np.std(epoch[26])),abs(np.std(epoch[27])),abs(np.std(epoch[28])),abs(np.std(epoch[29])),abs(np.std(epoch[30])),abs(np.std(epoch[31])),abs(np.std(epoch[32])),abs(np.std(epoch[33])),abs(np.std(epoch[34])),abs(np.std(epoch[35]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvfile = \"Features/features1.csv\"\n",
    "feature_names = ['Activity','Mobility','Complexity','Kurtosis','2nd Difference Mean','2nd Difference Max','Coeffiecient of Variation','Skewness','1st Difference Mean','1st Difference Max',\n",
    "          'Wavelet Approximate Mean','Wavelet Approximate Std Deviation','Wavelet Detailed Mean','Wavelet Detailed Std Deviation','Wavelet Approximate Energy','Wavelet Detailed Energy',\n",
    "          'Wavelet Approximate Entropy','Wavelet Detailed Entropy','Variance','Mean of Vertex to Vertex Slope','FFT Delta MaxPower','FFT Theta MaxPower','FFT Alpha MaxPower','FFT Beta MaxPower'\n",
    "          ]\n",
    "with open(csvfile, \"a\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    writer.writerow(feature_names) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joy/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:19: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "with open(csvfile, \"a\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n') \n",
    "    for subject in subjects:\n",
    "        \n",
    "        location_data  = data_files_location + '/' + subject + '_data.csv'\n",
    "        location_markers = data_files_location + '/' + subject + '_markers.csv'\n",
    "        \n",
    "        data = np.genfromtxt (location_data, delimiter=\",\")\n",
    "        markers = np.genfromtxt (location_markers, delimiter = \",\")\n",
    "        \n",
    "        for each_marker in markers:\n",
    "            starting_point = each_marker[0]\n",
    "            target = each_marker[1]\n",
    "            \n",
    "            if target>0 and target<=4:\n",
    "                sound_stimuli_begins = starting_point + (2*250)\n",
    "                visual_stimuli_begins = sound_stimuli_begins + 250\n",
    "                end_of_visual = visual_stimuli_begins + 1000\n",
    "                epoch = data[visual_stimuli_begins:end_of_visual,:]\n",
    "                \n",
    "                epoch = np.array(epoch)\n",
    "                epoch = np.transpose(epoch)\n",
    "                features = []\n",
    "                channels = 60\n",
    "                \n",
    "                #Band-pass filtered\n",
    "                (b, a) = signal.butter(3, np.array([8, 30])/ 100.00, 'bandpass')\n",
    "                filtered_epoch = signal.lfilter(b, a, epoch, 1)\n",
    "                \n",
    "                feature_list = wavelet_features(filtered_epoch,channels)\n",
    "                for feat in feature_list:\n",
    "                    features.append(feat)\n",
    "                    \n",
    "                feature_list  =  maxPwelch(filtered_epoch,100,channels)\n",
    "                for feat in feature_list:\n",
    "                    features.append(feat)\n",
    "                    \n",
    "                    \n",
    "                #Autoregressive model Coefficients\n",
    "                feature_list = autogressiveModelParametersBurg(filtered_epoch,channels)\n",
    "                for feat in feature_list:\n",
    "                    features.append(feat.real)\n",
    "                    \n",
    "                feature_list = find_variance(filtered_epoch,channels)\n",
    "                \n",
    "                for feat in feature_list:\n",
    "                    features.append(feat)\n",
    "                    \n",
    "                    \n",
    "                features.append(target);\n",
    "                writer.writerow(features)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
